# HR Analytics Pipeline Gepec 2.0 ğŸš€

## ğŸ“‹ Description

Complete HR analytics pipeline using Big Data and Machine Learning technologies to predict salaries and turnover risks of employees 

## ğŸ—ï¸ Architecture

```
HR Analytics Pipeline
â”œâ”€â”€ ğŸ² Synthetic data generation
â”œâ”€â”€ ğŸ¤– ML Models (Linear Regression + Random Forest)
â”œâ”€â”€ ğŸ“¡ Real-time streaming (Apache Kafka)
â”œâ”€â”€ â˜ï¸ Cloud storage (AWS S3)
â”œâ”€â”€ âš¡ Big Data processing (Apache Spark)
â””â”€â”€ ğŸ“Š Analytics and predictions
```

## ğŸ› ï¸ Technologies Used

- **Python 3.10** - Main language
- **Apache Spark** - Big Data processing
- **Apache Kafka** - Real-time streaming
- **AWS S3** - Cloud storage
- **Scikit-learn** - Machine Learning
- **Pandas/NumPy** - Data manipulation
- **MLflow** - Model tracking

## âš™ï¸ Installation

### 1. Prerequisites
- Python 3.10+
- Java 8+ (for Spark)
- Apache Kafka (optional, for streaming)
- AWS Account (optional, for S3)

### 2. Installing dependencies
```bash
# Create virtual environment
python -m venv venv_py310

# Activate environment (Windows)
venv_py310\Scripts\activate.bat

# Install dependencies
pip install -r requirements.txt
```

### 3. Configuration
1. Copy `.env` and adjust variables according to your environment
2. Configure your AWS credentials (optional)
3. Verify that Kafka is accessible (optional)

## ğŸš€ Usage

### Quick Start (Windows)
```bash
# Launch the interactive startup script
start_pipeline.bat
```

### Manual Execution
```bash
# Complete pipeline
python main.py

# Train models only
python -c "from src.ml_models import MLModelTrainer; trainer = MLModelTrainer(); trainer.train_all_models()"

# Generate synthetic data
python -c "from src.data_generator import SyntheticDataGenerator; gen = SyntheticDataGenerator(); data = gen.generate_employees(100); gen.save_to_files(data)"
```

## ğŸ“Š Included ML Models

### 1. Salary Prediction Model
- **Algorithm**: Linear Regression
- **Features**: Age, Experience, Education level, Department, etc.
- **Objective**: Predict annual salary in MAD

### 2. Turnover Risk Model
- **Algorithm**: Random Forest Classifier
- **Features**: Satisfaction, Performance, Tenure, Age, etc.
- **Objective**: Predict turnover risk (Low/High)

## ğŸ“ Project Structure

```
gepec2.0/
â”œâ”€â”€ ğŸ“„ main.py                    # Main script
â”œâ”€â”€ ğŸ“„ requirements.txt           # Python dependencies
â”œâ”€â”€ ğŸ“„ .env                       # Environment variables
â”œâ”€â”€ ğŸ“„ start_pipeline.bat         # Windows startup script
â”œâ”€â”€ ğŸ“„ README.md                  # Documentation
â”œâ”€â”€ ğŸ“„ employees_morocco_2024.csv # Main dataset
â”‚
â”œâ”€â”€ ğŸ“ config/
â”‚   â””â”€â”€ ğŸ“„ settings.py            # Central configuration
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“„ ml_models.py           # Machine Learning models
â”‚   â”œâ”€â”€ ğŸ“„ data_generator.py      # Synthetic data generator
â”‚   â”œâ”€â”€ ğŸ“„ kafka_producer.py      # Kafka producer
â”‚   â”œâ”€â”€ ğŸ“„ s3_handler.py          # AWS S3 handler
â”‚   â””â”€â”€ ğŸ“„ spark_processor.py     # Apache Spark processor
â”‚
â”œâ”€â”€ ğŸ“ data/                      # Generated data
â”œâ”€â”€ ğŸ“ models/                    # Saved ML models
â”œâ”€â”€ ğŸ“ logs/                      # Log files
â””â”€â”€ ğŸ“ venv_py310/                # Virtual environment
```

## ğŸ”§ Advanced Configuration

### Environment Variables (.env)
```bash
# AWS S3
AWS_ACCESS_KEY_ID=your_key
AWS_SECRET_ACCESS_KEY=your_secret
S3_BUCKET_NAME=hr-analytics-gepec

# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC_NAME=hr_analytics_topic

# Spark
SPARK_DRIVER_MEMORY=4g
SPARK_EXECUTOR_MEMORY=2g
```

### Model Customization
Modify parameters in `config/settings.py`:
```python
ML_CONFIG = {
    'salary_model': {
        'features': ['Age', 'Annees_Experience_Totale', ...],
        'test_size': 0.2,
        'random_state': 42
    },
    'turnover_model': {
        'n_estimators': 100,
        'max_depth': 10,
        ...
    }
}
```

## ğŸ“ˆ Main Features

### âœ… Synthetic Data Generation
- Realistic employee data based on Moroccan context
- Consistency of relationships between variables
- Export to CSV, Excel and JSON

### âœ… Machine Learning
- Automatic model training
- Evaluation and performance metrics
- Model saving and loading
- Result visualizations

### âœ… Real-Time Streaming
- Apache Kafka integration
- Batch and streaming processing
- Error handling and automatic retry

### âœ… Cloud Storage
- Automatic upload to AWS S3
- Multi-format support (CSV, Parquet, JSON)
- Metadata and versioning
- Pre-signed URLs for sharing

### âœ… Big Data Analytics
- Distributed processing with Apache Spark
- Real-time analytics metrics
- Large-volume predictions
- Performance optimizations

## ğŸ” Monitoring and Logs

Logs are automatically generated in the `logs/` folder with:
- Operation timestamps
- Performance metrics
- Errors and warnings
- Prediction results

## ğŸ¤ Contribution

1. Fork the project
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ Support


## ğŸ“œ License

This project is under MIT license - see the [LICENSE](LICENSE) file for more details.

## ğŸ™ Acknowledgments

- Gepec Data Science Team
- Apache Spark Community
- Open source contributors

---

**Gepec 2.0 HR Analytics Pipeline** - Transform your HR data into actionable insights! ğŸš€