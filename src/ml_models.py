#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module d'entra√Ænement des mod√®les ML
===================================

Ce module contient les classes pour entra√Æner :
1. Mod√®le de r√©gression lin√©aire pour pr√©dire les salaires
2. Mod√®le Random Forest pour pr√©dire le risque de d√©part

Auteur: √âquipe Data Science Gepec 2.0
"""

import pandas as pd
import numpy as np
import joblib
import logging
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# Import des configurations
import sys
sys.path.append(str(Path(__file__).parent.parent))
from config.settings import ML_CONFIG, CATEGORICAL_MAPPINGS, MODELS_DIR, PROJECT_ROOT

class MLModelTrainer:
    """
    Classe principale pour l'entra√Ænement des mod√®les ML
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.models_dir = MODELS_DIR
        self.models_dir.mkdir(exist_ok=True)
        self.salary_model = None
        self.turnover_model = None
        self.label_encoders = {}
        
    def load_data(self):
        """
        Charge et pr√©processe les donn√©es du fichier CSV
        """
        try:
            # Charger le dataset
            data_path = PROJECT_ROOT / "employees_morocco_2024.csv"
            df = pd.read_csv(data_path)
            
            self.logger.info(f"üìä Dataset charg√©: {len(df)} lignes, {len(df.columns)} colonnes")
            
            # Nettoyage des donn√©es
            df = self._clean_data(df)
            
            # Encodage des variables cat√©gorielles
            df = self._encode_categorical_variables(df)
            
            return df
            
        except Exception as e:
            self.logger.error(f"Erreur lors du chargement des donn√©es: {str(e)}")
            raise
    
    def _clean_data(self, df):
        """
        Nettoie les donn√©es en traitant les valeurs manquantes et aberrantes
        """
        # Supprimer les doublons
        initial_len = len(df)
        df = df.drop_duplicates()
        if len(df) < initial_len:
            self.logger.info(f"üßπ {initial_len - len(df)} doublons supprim√©s")
        
        # Convertir les dates
        df['Date_Embauche'] = pd.to_datetime(df['Date_Embauche'])
        df['Date_Estimee_Retraite'] = pd.to_datetime(df['Date_Estimee_Retraite'])
        
        # Traiter les valeurs manquantes dans Risque_Depart
        if 'Risque_Depart' in df.columns:
            missing_count = df['Risque_Depart'].isna().sum()
            if missing_count > 0:
                # Remplacer les valeurs manquantes par "Faible" (valeur par d√©faut)
                df['Risque_Depart'] = df['Risque_Depart'].fillna('Faible')
                self.logger.info(f"üßπ {missing_count} valeurs manquantes dans Risque_Depart remplac√©es par 'Faible'")
        
        # Nettoyer les salaires (supprimer les valeurs aberrantes)
        Q1 = df['Salaire_Annuel_MAD'].quantile(0.25)
        Q3 = df['Salaire_Annuel_MAD'].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        before_len = len(df)
        df = df[(df['Salaire_Annuel_MAD'] >= lower_bound) & 
                (df['Salaire_Annuel_MAD'] <= upper_bound)]
        
        if len(df) < before_len:
            self.logger.info(f"üßπ {before_len - len(df)} valeurs aberrantes de salaires supprim√©es")
        
        return df
    
    def _encode_categorical_variables(self, df):
        """
        Encode les variables cat√©gorielles en utilisant les mappings d√©finis
        """
        df_encoded = df.copy()
        
        for column, mapping in CATEGORICAL_MAPPINGS.items():
            if column in df_encoded.columns:
                # V√©rifier les valeurs uniques avant encodage
                unique_values = df_encoded[column].unique()
                unmapped_values = [val for val in unique_values if val not in mapping and pd.notna(val)]
                
                if unmapped_values:
                    self.logger.warning(f"‚ö†Ô∏è Valeurs non mapp√©es dans {column}: {unmapped_values}")
                    # Pour Risque_Depart, assigner les valeurs non mapp√©es √† "Faible" (0)
                    if column == 'Risque_Depart':
                        for unmapped_val in unmapped_values:
                            mapping[unmapped_val] = 0  # Assigner √† "Faible"
                        self.logger.info(f"üîß Valeurs non mapp√©es dans {column} assign√©es √† 'Faible'")
                
                df_encoded[column] = df_encoded[column].map(mapping)
                
                # V√©rifier et traiter les NaN apr√®s encodage
                nan_count = df_encoded[column].isna().sum()
                if nan_count > 0:
                    if column == 'Risque_Depart':
                        df_encoded[column] = df_encoded[column].fillna(0)  # Faible = 0
                        self.logger.info(f"üßπ {nan_count} valeurs NaN dans {column} remplac√©es par 0 (Faible)")
                    else:
                        df_encoded[column] = df_encoded[column].fillna(df_encoded[column].mode()[0] if len(df_encoded[column].mode()) > 0 else 0)
                        self.logger.info(f"üßπ {nan_count} valeurs NaN dans {column} remplac√©es par la mode")
                
                self.logger.info(f"üîÑ Variable {column} encod√©e")
        
        # Encoder d'autres variables cat√©gorielles avec LabelEncoder
        categorical_cols = ['Ville', 'Niveau_Etudes', 'Etablissement_Formation', 
                           'Departement', 'Poste', 'Competence_Principale', 
                           'Niveau_Competence_Principale', 'Role_Futur_Souhaite']
        
        for col in categorical_cols:
            if col in df_encoded.columns:
                le = LabelEncoder()
                df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))
                self.label_encoders[col] = le
                
        return df_encoded
    
    def train_salary_model(self, df):
        """
        Entra√Æne le mod√®le de r√©gression lin√©aire pour pr√©dire les salaires
        """
        self.logger.info("üéØ Entra√Ænement du mod√®le de pr√©diction des salaires...")
        
        config = ML_CONFIG['salary_model']
        
        # Pr√©parer les features et target
        feature_cols = config['features']
        target_col = config['target']
        
        # V√©rifier que toutes les colonnes existent
        missing_cols = [col for col in feature_cols if col not in df.columns]
        if missing_cols:
            self.logger.warning(f"Colonnes manquantes: {missing_cols}")
            feature_cols = [col for col in feature_cols if col in df.columns]
        
        X = df[feature_cols]
        y = df[target_col]
        
        # Division train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=config['test_size'], random_state=config['random_state']
        )
        
        # Entra√Ænement du mod√®le
        self.salary_model = LinearRegression()
        self.salary_model.fit(X_train, y_train)
        
        # √âvaluation
        y_pred = self.salary_model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        self.logger.info(f"üìà Mod√®le salaire - MSE: {mse:.2f}, R¬≤: {r2:.3f}")
        
        # Sauvegarde du mod√®le
        model_path = self.models_dir / "salary_model.pkl"
        joblib.dump(self.salary_model, model_path)
        self.logger.info(f"üíæ Mod√®le de salaire sauvegard√©: {model_path}")
        
        # Visualisation des r√©sultats
        self._plot_salary_results(y_test, y_pred)
        
        return {
            'mse': mse,
            'r2': r2,
            'features': feature_cols,
            'n_samples_train': len(X_train),
            'n_samples_test': len(X_test)
        }
    
    def train_turnover_model(self, df):
        """
        Entra√Æne le mod√®le Random Forest pour pr√©dire le risque de d√©part
        """
        self.logger.info("üéØ Entra√Ænement du mod√®le de pr√©diction du risque de d√©part...")
        
        config = ML_CONFIG['turnover_model']
        
        # Pr√©parer les features et target
        feature_cols = config['features']
        target_col = config['target']
        
        # V√©rifier que toutes les colonnes existent
        missing_cols = [col for col in feature_cols if col not in df.columns]
        if missing_cols:
            self.logger.warning(f"Colonnes manquantes: {missing_cols}")
            feature_cols = [col for col in feature_cols if col in df.columns]
        
        X = df[feature_cols]
        y = df[target_col]
        
        # Division train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=config['test_size'], random_state=config['random_state']
        )
        
        # Entra√Ænement du mod√®le
        self.turnover_model = RandomForestClassifier(
            n_estimators=config['n_estimators'],
            max_depth=config['max_depth'],
            random_state=config['random_state']
        )
        self.turnover_model.fit(X_train, y_train)
        
        # √âvaluation
        y_pred = self.turnover_model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        self.logger.info(f"üìà Mod√®le risque d√©part - Accuracy: {accuracy:.3f}")
        self.logger.info(f"üìä Rapport de classification:\n{classification_report(y_test, y_pred)}")
        
        # Sauvegarde du mod√®le
        model_path = self.models_dir / "turnover_model.pkl"
        joblib.dump(self.turnover_model, model_path)
        self.logger.info(f"üíæ Mod√®le de risque de d√©part sauvegard√©: {model_path}")
        
        # Visualisation des r√©sultats
        self._plot_turnover_results(y_test, y_pred)
        
        return {
            'accuracy': accuracy,
            'features': feature_cols,
            'n_samples_train': len(X_train),
            'n_samples_test': len(X_test)
        }
    
    def _plot_salary_results(self, y_test, y_pred):
        """
        Cr√©e des graphiques pour visualiser les r√©sultats du mod√®le de salaire
        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Graphique de corr√©lation pr√©dictions vs r√©el
        ax1.scatter(y_test, y_pred, alpha=0.6)
        ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        ax1.set_xlabel('Salaire R√©el (MAD)')
        ax1.set_ylabel('Salaire Pr√©dit (MAD)')
        ax1.set_title('Pr√©dictions vs R√©alit√© - Mod√®le Salaire')
        
        # Histogramme des r√©sidus
        residuals = y_test - y_pred
        ax2.hist(residuals, bins=30, alpha=0.7)
        ax2.set_xlabel('R√©sidus (MAD)')
        ax2.set_ylabel('Fr√©quence')
        ax2.set_title('Distribution des R√©sidus')
        
        plt.tight_layout()
        plt.savefig(self.models_dir / 'salary_model_evaluation.png', dpi=300, bbox_inches='tight')
        plt.close()
        
    def _plot_turnover_results(self, y_test, y_pred):
        """
        Cr√©e des graphiques pour visualiser les r√©sultats du mod√®le de turnover
        """
        from sklearn.metrics import confusion_matrix
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # Matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1)
        ax1.set_xlabel('Pr√©dictions')
        ax1.set_ylabel('R√©alit√©')
        ax1.set_title('Matrice de Confusion - Risque de D√©part')
        
        # Importance des features
        if hasattr(self.turnover_model, 'feature_importances_'):
            features = ML_CONFIG['turnover_model']['features']
            importances = self.turnover_model.feature_importances_
            
            feature_importance = pd.DataFrame({
                'feature': features,
                'importance': importances
            }).sort_values('importance', ascending=True)
            
            ax2.barh(feature_importance['feature'], feature_importance['importance'])
            ax2.set_xlabel('Importance')
            ax2.set_title('Importance des Variables - Random Forest')
        
        plt.tight_layout()
        plt.savefig(self.models_dir / 'turnover_model_evaluation.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def train_all_models(self):
        """
        Entra√Æne tous les mod√®les ML
        """
        try:
            # Charger les donn√©es
            df = self.load_data()
            
            # Entra√Æner le mod√®le de salaire
            salary_results = self.train_salary_model(df)
            
            # Entra√Æner le mod√®le de turnover
            turnover_results = self.train_turnover_model(df)
            
            # Sauvegarder les encodeurs
            encoders_path = self.models_dir / "label_encoders.pkl"
            joblib.dump(self.label_encoders, encoders_path)
            
            # R√©sum√© des r√©sultats
            results_summary = {
                'salary_model': salary_results,
                'turnover_model': turnover_results,
                'timestamp': pd.Timestamp.now().isoformat()
            }
            
            self.logger.info("‚úÖ Tous les mod√®les ont √©t√© entra√Æn√©s avec succ√®s!")
            self.logger.info(f"üìä R√©sultats du mod√®le salaire: R¬≤ = {salary_results['r2']:.3f}")
            self.logger.info(f"üìä R√©sultats du mod√®le turnover: Accuracy = {turnover_results['accuracy']:.3f}")
            
            # Affichage des r√©sultats dans la console
            print("\n" + "="*80)
            print("üéØ R√âSULTATS DE L'ENTRA√éNEMENT DES MOD√àLES ML - GEPEC 2.0")
            print("="*80)
            print(f"üìà MOD√àLE DE PR√âDICTION DES SALAIRES:")
            print(f"   ‚Ä¢ R¬≤ Score: {salary_results['r2']:.3f}")
            print(f"   ‚Ä¢ MSE: {salary_results['mse']:,.2f} MAD")
            print(f"   ‚Ä¢ √âchantillons d'entra√Ænement: {salary_results['n_samples_train']}")
            print(f"   ‚Ä¢ √âchantillons de test: {salary_results['n_samples_test']}")
            print(f"   ‚Ä¢ Variables utilis√©es: {len(salary_results['features'])}")
            
            print(f"\nüîÑ MOD√àLE DE PR√âDICTION DU TURNOVER:")
            print(f"   ‚Ä¢ Accuracy: {turnover_results['accuracy']:.3f}")
            print(f"   ‚Ä¢ √âchantillons d'entra√Ænement: {turnover_results['n_samples_train']}")
            print(f"   ‚Ä¢ √âchantillons de test: {turnover_results['n_samples_test']}")
            print(f"   ‚Ä¢ Variables utilis√©es: {len(turnover_results['features'])}")
            
            print(f"\nüíæ FICHIERS G√âN√âR√âS:")
            print(f"   ‚Ä¢ Mod√®le salaire: {self.models_dir}/salary_model.pkl")
            print(f"   ‚Ä¢ Mod√®le turnover: {self.models_dir}/turnover_model.pkl")
            print(f"   ‚Ä¢ Encodeurs: {self.models_dir}/label_encoders.pkl")
            print(f"   ‚Ä¢ √âvaluation salaire: {self.models_dir}/salary_model_evaluation.png")
            print(f"   ‚Ä¢ √âvaluation turnover: {self.models_dir}/turnover_model_evaluation.png")
            print("="*80)
            print("‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS!")
            print("="*80)
            
            return results_summary
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de l'entra√Ænement des mod√®les: {str(e)}")
            raise

if __name__ == "__main__":
    trainer = MLModelTrainer()
    trainer.train_all_models()